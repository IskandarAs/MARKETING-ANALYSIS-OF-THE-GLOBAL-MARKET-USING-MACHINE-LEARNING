>## Machine-Learning-of-Consumer-Market
<p align="center">
  <img src="https://cdn.goconqr.com/uploads/media/image/9392203/bd87aefc-9f7f-4a52-9982-b5365e3f81db.jpg?raw=true" alt="Sublime's custom image"/>
</p>


**Use advanced Machine Learning Algorithms for consumer market**
- [x] **Random Forest**
- [x] **XGBoost(eXtreme Gradient Boosting)**
- [x] **Light GBM(Light Gradient Boosting Machine)**

**Problem statement**
- [x] **Find the best way to sell a product**
- [x] **Creating a model to evaluate performance features Total Profit by model**
- [x] **Forecasting total profit over 5 years by sales channel**

**Description Methods**


- [x] **1. Random Forest**

A Random Forest is an ensemble technique capable of performing both regression and classification tasks with the use of multiple decision trees and a technique called Bootstrap and Aggregation, commonly known as bagging. The basic idea behind this is to combine multiple decision trees in determining the final output rather than relying on individual decision trees. Random Forest has multiple decision trees as base learning models.

- [x] **2. XGBoost**

XGBoost is an open source library providing a high-performance implementation of gradient boosted decision trees. An underlying C++ codebase combined with a Python interface sitting on top makes for an extremely powerful yet easy to implement package.

XGBoost Features

The library is laser-focused on computational speed and model performance, as such, there are few frills.

Model Features

Three main forms of gradient boosting are supported:

- Gradient Boosting
- Stochastic Gradient Boosting
- Regularized Gradient Boosting
 
 System Features
 
- For use of a range of computing environments this library provides-
- Parallelization of tree construction
- Distributed Computing for training very large models
- Cache Optimization of data structures and algorithm

- [x] **3. LightGBM**

LightGBM is a gradient boosting framework that uses tree based learning algorithms. It is designed to be distributed and efficient with the following advantages:

- Faster training speed and higher efficiency.
- Lower memory usage.
- Better accuracy.
- Support of parallel and GPU learning.
- Capable of handling large-scale data.
- Benefitting from these advantages, LightGBM is being widely-used in many winning solutions of machine learning competitions.

Comparison experiments on public datasets show that LightGBM can outperform existing boosting frameworks on both efficiency and accuracy, with significantly lower memory consumption. What's more, parallel experiments show that LightGBM can achieve a linear speed-up by using multiple machines for training in specific settings.

